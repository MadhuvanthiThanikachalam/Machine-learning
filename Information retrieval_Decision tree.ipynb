{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DT_MIRT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2MpJ58fnDjK/Y7zyZdZYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadhuvanthiThanikachalam/Machine-learning/blob/main/Information%20retrieval_Decision%20tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jew5HEyBDu7d"
      },
      "source": [
        "import string\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('always')  # This makes it so that each warning is only shown once. \n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPHKexLMDu95"
      },
      "source": [
        "def encode(source):\n",
        "\tle = LabelEncoder()\n",
        "\tcenter = np.array(source['a4'])\n",
        "\tclasses = le.fit_transform(source[['class']])\n",
        "\tclass_inverted = le.inverse_transform((classes))\n",
        "\tclass_map = {}\n",
        "\n",
        "\tfor i in range(len(classes)):\n",
        "\t    if class_inverted[i] not in class_map:\n",
        "\t        class_map[class_inverted[i]] = [classes[i], 1]\n",
        "\t    else:\n",
        "\t        class_map[class_inverted[i]][1] += 1\n",
        "\t\n",
        "\tlowest = float('inf') #Set it to a theoretical upper bound\n",
        "\tlowest_class = \"\"\n",
        "\t\n",
        "\tfor key in class_map: #Find the lowest\n",
        "\t\tif class_map.get(key)[1] < lowest:\n",
        "\t\t\tlowest = class_map.get(key)[1]\n",
        "\t\t\tlowest_class = class_map.get(key)[0]\n",
        "\t\n",
        "\t\t\tprint(class_map)\n",
        "\t\t\tprint(class_map.get(key)[1])\n",
        "\t\n",
        "\tword_dict = {}\n",
        "\tfinal_list = []\n",
        "\n",
        "\tfor i in range(len(center)):\n",
        "\t\tif center[i] not in word_dict:\n",
        "\t\t\tword_dict[center[i]] = classes[i]\n",
        "\n",
        "\tselected_attributes = source[['a1', 'a2', 'a3', 'a4', 'a5', 'a6']].to_numpy() #Use the leave one out method here by removing attributes.\n",
        "\n",
        "\tfor row in selected_attributes: \n",
        "\t\tlocal_list = []\n",
        "\t\tfor i in row:\n",
        "\t\t\tif i in word_dict:\n",
        "\t\t\t\tlocal_list.append(word_dict.get(i))\n",
        "\t\t\telse:\n",
        "\t\t\t\tlocal_list.append(lowest_class)\n",
        "\t\tfinal_list.append(local_list)\n",
        "\n",
        "\n",
        "\tx = scipy.sparse.csr_matrix(final_list)\n",
        "\ty = scipy.sparse.csr_matrix(classes)\n",
        "\n",
        "\treturn x,y #return two compressed sparse row matrices with unique value IDs for each class.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2jWoepHEQU1"
      },
      "source": [
        "def trainer(classifier, x_train, x_test, y_train, y_test):\n",
        "\n",
        "\n",
        "    classifier.fit(x_train.todense(), y_train)\n",
        "    y_pred = classifier.predict(x_test.todense())\n",
        "\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "    precision = precision_score(y_test, y_pred, average=\"macro\", labels=np.unique(y_pred)) #Unique labels that fixes a y_pred error\n",
        "    recall = recall_score(y_test, y_pred, average=\"macro\", labels=np.unique(y_pred))\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return f1, precision, recall, accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkgQK3bEYw1"
      },
      "source": [
        "def trainDTC(x,y):\n",
        "\tf1List = list()\n",
        "\tprecisionList = list()\n",
        "\trecallList = list()\n",
        "\taccuracyList= list()\n",
        "\t\n",
        "\t# n_splits = 5, we are using 5-fold cross validation\n",
        "\tkf = KFold(n_splits = 5)\n",
        "\n",
        "\tfor train_index, test_index in kf.split(x):\n",
        "\t\tx_train, x_test = x[train_index], x[test_index]\n",
        "\t\ty_train = []\n",
        "\t\ty_test = []\n",
        "\t\tfor i in train_index:\n",
        "\t\t\ty_train.append(y[0, i])\n",
        "\t\tfor i in test_index:\n",
        "\t\t\ty_test.append(y[0, i])\n",
        "\t\tf1, precision, recall, accuracy= trainer(DecisionTreeClassifier(random_state=0), x_train, x_test, y_train, y_test)\n",
        "\t\tf1List.append(f1)\n",
        "\t\tprecisionList.append(precision)\n",
        "\t\trecallList.append(recall)\n",
        "\t\taccuracyList.append(accuracy)\n",
        "\n",
        "\n",
        "\taverageAccuracy = np.mean(accuracyList)\n",
        "\taveragePrecision = np.mean(precisionList)\n",
        "\taverageF1 = np.mean(f1List)\n",
        "\taverageRecall = np.mean(recallList)\n",
        "\tprint(\"Decision Tree Classifier Average Accuracy for: {}\".format(averageAccuracy))\n",
        "\tprint(\"Decision Tree Classifier Average Precision for: {}\".format(averagePrecision))\n",
        "\tprint(\"Decision Tree Classifier Average F1 for: {}\".format(averageF1))\n",
        "\tprint(\"Decision Tree Classifier Average Recall for: {}\".format(averageRecall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeQj0c25EYy7",
        "outputId": "665ab369-18d4-4ca4-9726-c22b22469c34"
      },
      "source": [
        "def build():\n",
        "\tdata = pd.read_csv('pos-eng-5000.data.csv')\n",
        "\tprint(data)\n",
        "\tx, y = encode(data)\n",
        "\ttrainDTC(x,y)\n",
        "\n",
        "\n",
        "build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             a1         a2         a3  ...       a6      a7   class\n",
            "0             _          _          _  ...  remains  closed      DT\n",
            "1             _          _        The  ...   closed  PERIOD      NN\n",
            "2             _        The  cafeteria  ...   PERIOD       _     VBZ\n",
            "3           The  cafeteria    remains  ...        _       _      JJ\n",
            "4     cafeteria    remains     closed  ...        _       _  PERIOD\n",
            "...         ...        ...        ...  ...      ...     ...     ...\n",
            "4995       side         to       side  ...   frenzy  PERIOD      IN\n",
            "4996         to       side         in  ...   PERIOD       _      DT\n",
            "4997       side         in          a  ...        _       _      NN\n",
            "4998         in          a     frenzy  ...        _       _  PERIOD\n",
            "4999          _          _          _  ...     seem      to     PRP\n",
            "\n",
            "[5000 rows x 8 columns]\n",
            "{'DT': [8, 447], 'NN': [16, 648], 'VBZ': [37, 93], 'JJ': [12, 328], 'PERIOD': [21, 234], 'NNS': [19, 269], 'VBD': [33, 222], 'IN': [11, 487], 'EX': [9, 12], 'MD': [15, 46], 'RB': [25, 225], 'VB': [32, 136], 'POS': [22, 30], 'VBG': [34, 75], 'RP': [28, 14], 'VBN': [35, 118], 'VBP': [36, 63], 'NNP': [17, 420], 'NNPS': [18, 16], 'CC': [2, 126], 'COMMA': [5, 271], 'WDT': [38, 14], 'CD': [3, 141], 'PRP': [23, 141], 'JJR': [13, 15], 'PRPSTR': [24, 46], 'STR': [29, 37], 'TO': [30, 117], 'WRB': [41, 23], 'COLON': [4, 40], 'PDT': [20, 2], 'DBQ': [6, 42], 'DQ': [7, 39], 'WP': [39, 15], 'UH': [31, 2], 'JJS': [14, 8], 'RBR': [26, 14], 'WPSTR': [40, 3], '(': [0, 6], ')': [1, 6], 'FW': [10, 4], 'RBS': [27, 5]}\n",
            "447\n",
            "{'DT': [8, 447], 'NN': [16, 648], 'VBZ': [37, 93], 'JJ': [12, 328], 'PERIOD': [21, 234], 'NNS': [19, 269], 'VBD': [33, 222], 'IN': [11, 487], 'EX': [9, 12], 'MD': [15, 46], 'RB': [25, 225], 'VB': [32, 136], 'POS': [22, 30], 'VBG': [34, 75], 'RP': [28, 14], 'VBN': [35, 118], 'VBP': [36, 63], 'NNP': [17, 420], 'NNPS': [18, 16], 'CC': [2, 126], 'COMMA': [5, 271], 'WDT': [38, 14], 'CD': [3, 141], 'PRP': [23, 141], 'JJR': [13, 15], 'PRPSTR': [24, 46], 'STR': [29, 37], 'TO': [30, 117], 'WRB': [41, 23], 'COLON': [4, 40], 'PDT': [20, 2], 'DBQ': [6, 42], 'DQ': [7, 39], 'WP': [39, 15], 'UH': [31, 2], 'JJS': [14, 8], 'RBR': [26, 14], 'WPSTR': [40, 3], '(': [0, 6], ')': [1, 6], 'FW': [10, 4], 'RBS': [27, 5]}\n",
            "93\n",
            "{'DT': [8, 447], 'NN': [16, 648], 'VBZ': [37, 93], 'JJ': [12, 328], 'PERIOD': [21, 234], 'NNS': [19, 269], 'VBD': [33, 222], 'IN': [11, 487], 'EX': [9, 12], 'MD': [15, 46], 'RB': [25, 225], 'VB': [32, 136], 'POS': [22, 30], 'VBG': [34, 75], 'RP': [28, 14], 'VBN': [35, 118], 'VBP': [36, 63], 'NNP': [17, 420], 'NNPS': [18, 16], 'CC': [2, 126], 'COMMA': [5, 271], 'WDT': [38, 14], 'CD': [3, 141], 'PRP': [23, 141], 'JJR': [13, 15], 'PRPSTR': [24, 46], 'STR': [29, 37], 'TO': [30, 117], 'WRB': [41, 23], 'COLON': [4, 40], 'PDT': [20, 2], 'DBQ': [6, 42], 'DQ': [7, 39], 'WP': [39, 15], 'UH': [31, 2], 'JJS': [14, 8], 'RBR': [26, 14], 'WPSTR': [40, 3], '(': [0, 6], ')': [1, 6], 'FW': [10, 4], 'RBS': [27, 5]}\n",
            "12\n",
            "{'DT': [8, 447], 'NN': [16, 648], 'VBZ': [37, 93], 'JJ': [12, 328], 'PERIOD': [21, 234], 'NNS': [19, 269], 'VBD': [33, 222], 'IN': [11, 487], 'EX': [9, 12], 'MD': [15, 46], 'RB': [25, 225], 'VB': [32, 136], 'POS': [22, 30], 'VBG': [34, 75], 'RP': [28, 14], 'VBN': [35, 118], 'VBP': [36, 63], 'NNP': [17, 420], 'NNPS': [18, 16], 'CC': [2, 126], 'COMMA': [5, 271], 'WDT': [38, 14], 'CD': [3, 141], 'PRP': [23, 141], 'JJR': [13, 15], 'PRPSTR': [24, 46], 'STR': [29, 37], 'TO': [30, 117], 'WRB': [41, 23], 'COLON': [4, 40], 'PDT': [20, 2], 'DBQ': [6, 42], 'DQ': [7, 39], 'WP': [39, 15], 'UH': [31, 2], 'JJS': [14, 8], 'RBR': [26, 14], 'WPSTR': [40, 3], '(': [0, 6], ')': [1, 6], 'FW': [10, 4], 'RBS': [27, 5]}\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Classifier Average Accuracy for: 0.9513999999999999\n",
            "Decision Tree Classifier Average Precision for: 0.8867489898977441\n",
            "Decision Tree Classifier Average F1 for: 0.8528961722781855\n",
            "Decision Tree Classifier Average Recall for: 0.910607069696631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpNRRjNEY2S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPfw5cUDvAT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0JkoAwHDvD1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}