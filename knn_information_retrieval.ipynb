{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knn_information retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadhuvanthiThanikachalam/Machine-learning/blob/main/knn_information_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLtYT4mdcqUe",
        "outputId": "b2cfeed8-9349-416d-d5a2-08401a0da918"
      },
      "source": [
        "# Importing libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        " \n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        " \n",
        "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\n",
        "def clean(doc):\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
        "    y = processed.split()\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDcWkTuHTCp2"
      },
      "source": [
        "**PRINTING THE DOCUMENT** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWC_GPlQdK55",
        "outputId": "25a7ded4-9d5e-45e8-dbba-2d9e91f3a543"
      },
      "source": [
        "print (\"There are 10 sentences of following three classes on which K-NN classification is performed: \\n1. Cricket \\n2. Artificial Intelligence \\n3. Chemistry\\n\")\n",
        "path = \"/content/drive/MyDrive/Sentences.txt\"\n",
        "train_clean_sentences = []\n",
        "fp = open(path,'r')    \n",
        "for line in fp:\n",
        "    line = line.strip()\n",
        "    cleaned = clean(line)\n",
        "    cleaned = ' '.join(cleaned)\n",
        "    train_clean_sentences.append(cleaned)\n",
        "  \n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(train_clean_sentences)\n",
        " \n",
        "# Creating true labels for 30 training sentences\n",
        "y_train = np.zeros(30)\n",
        "y_train[10:20] = 1\n",
        "y_train[20:30] = 2\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 10 sentences of following three classes on which K-NN classification is performed: \n",
            "1. Cricket \n",
            "2. Artificial Intelligence \n",
            "3. Chemistry\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQrrn8Z9dxK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b40fa70-8aa0-4e87-8020-76c9f8d80561"
      },
      "source": [
        "# Clustering the document with KNN classifier\n",
        "modelknn = KNeighborsClassifier(n_neighbors=5)\n",
        "modelknn.fit(X,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzOjcKbGd1fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dd338d-1f16-470c-c712-71b47985e1aa"
      },
      "source": [
        "# Predicting it on test data : Testing Phase\n",
        "test_sentences = [\"Chemical compunds are used for preparing bombs based on some reactions\",\\\n",
        "\"Cricket is a boring game where the batsman only enjoys the game\",\\\n",
        "\"Machine learning is a area of Artificial intelligence\"]\n",
        " \n",
        "test_clean_sentence = []\n",
        "for test in test_sentences:\n",
        "  cleaned_test = clean(test)\n",
        "  cleaned = ' '.join(cleaned_test)\n",
        "  cleaned = re.sub(r\"\\d+\",\"\",cleaned)\n",
        "  test_clean_sentence.append(cleaned)\n",
        " \n",
        "Test = vectorizer.transform(test_clean_sentence)\n",
        " \n",
        "true_test_labels = ['Cricket','AI','Chemistry']\n",
        "predicted_labels_knn = modelknn.predict(Test) \n",
        "print (\"\\nBelow 3 sentences will be predicted against the learned nieghbourhood and learned clusters:\\n1. \",\\\n",
        "test_sentences[0],\"\\n2. \",test_sentences[1],\"\\n3. \",test_sentences[2])\n",
        "print (\"\\n PREDICTIONS BY KNN\")\n",
        "print (\"\\n\",test_sentences[0],\":\",true_test_labels[np.int(predicted_labels_knn[0])],\\\n",
        "\"\\n\",test_sentences[1],\":\",true_test_labels[np.int(predicted_labels_knn[1])],\\\n",
        "\"\\n\",test_sentences[2],\":\",true_test_labels[np.int(predicted_labels_knn[2])])\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Below 3 sentences will be predicted against the learned nieghbourhood and learned clusters:\n",
            "1.  Chemical compunds are used for preparing bombs based on some reactions \n",
            "2.  Cricket is a boring game where the batsman only enjoys the game \n",
            "3.  Machine learning is a area of Artificial intelligence\n",
            "\n",
            " PREDICTIONS BY KNN\n",
            "\n",
            " Chemical compunds are used for preparing bombs based on some reactions : Chemistry \n",
            " Cricket is a boring game where the batsman only enjoys the game : Cricket \n",
            " Machine learning is a area of Artificial intelligence : AI\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}